"""
M√≥dulo: budget_reader
------------------------

Respons√°vel por localizar e extrair, de forma robusta e independente de posi√ß√£o,
a tabela principal de itens de or√ßamento no padr√£o utilizado pelas construtoras
(GOT), normalmente presente na aba "LPU" das planilhas recebidas.

Este m√≥dulo foi projetado para suportar arquivos enviados por diferentes fornecedores.

üß© O que este m√≥dulo faz:
-------------------------
1) L√™ a aba "LPU" como planilha bruta, sem assumir header fixo.
2) Localiza dinamicamente o cabe√ßalho da tabela contendo as colunas:

   Filtro | ID | Descri√ß√£o | Un. | Unit√°rio | Coment√°rio | Quantidade | Total

3) Extrai somente a tabela ‚Äî ignorando cabe√ßalhos superiores, metadados e rodap√©s.
4) Normaliza e limpa linhas vazias ou inv√°lidas.
5) Disponibiliza as seguintes fun√ß√µes:

    - ler_planilha_tabela_orcamento(caminho_arquivo, nome_aba="LPU"):
         Fun√ß√£o principal para ingest√£o de um arquivo no padr√£o das construtoras.

   - localizar_tabela(df):
         Detecta a posi√ß√£o (linha, coluna) onde o cabe√ßalho se inicia.

   - extrair_tabela(df, header_row, first_col):
         Extrai todas as linhas subsequentes da tabela at√© as linhas vazias.

üéØ Por que este m√≥dulo √© essencial:
----------------------------------
- As planilhas reais apresentam alta variabilidade de layout.
- A posi√ß√£o da tabela nunca √© garantida: pode estar na linha 10, 20, 40 ou mais.
- O verificador precisa garantir parsing est√°vel antes de aplicar regras de IA.
- Pessoas usu√°rias enviam arquivos com linhas extras, logos, disclaimers etc.
- Minimiza erros de ingest√£o e padroniza o fluxo interno do Verificador Inteligente.

üöÄ Benef√≠cios para o Verificador Inteligente de Or√ßamentos:
-----------------------------------------------------------
- Padroniza leitura ‚Üí menos erros nas etapas determin√≠sticas.
- Permite parsing massivo de or√ßamentos (processamento di√°rio / batch).
- Suporta testes automatizados com grande variedade de layouts reais.
- Fornece uma base estruturada para agentes de IA avaliarem pre√ßos, quantidades,
  desvios e itens fora da LPU.

üìÅ Localiza√ß√£o:
--------------
O m√≥dulo faz parte da arquitetura "utils/", permitindo reutiliza√ß√£o limpa em:

- CLI (rich)
- Orquestra√ß√µes de agentes
- Fluxos Streamlit
- Pipelines via Step Functions / Lambda
- Testes automatizados

"""

__author__ = "Emerson V. Rafael (emervin)"
__copyright__ = "Verificador Inteligente de Or√ßamentos de Obras"
__credits__ = ["Emerson V. Rafael", "Lucas Ken", "Clarissa Simoyama"]
__license__ = "MIT"
__version__ = "1.0.0"
__maintainer__ = "Emerson V. Rafael (emervin), Lucas Ken (kushida), Clarissa Simoyama (simoyam)"
__squad__ = "DataCraft"
__email__ = "emersonssmile@gmail.com"
__status__ = "Production"

import math
import sys
from pathlib import Path
from typing import Union, Optional, List, Tuple, Dict, Any

import pandas as pd
from pydantic.dataclasses import dataclass

# Adicionar src ao path
base_dir = Path(__file__).parents[4]
sys.path.insert(0, str(Path(base_dir, "src")))

from config.config_logger import logger
from utils.data.data_functions import read_data

# Constantes centralizadas
DEFAULT_SHEET_NAME = "LPU"  # Nome padr√£o da aba a ser lida
EXPECTED_COLUMNS = [
    "Filtro",  # Coluna que indica se a linha deve ser filtrada
    "ID",  # Identificador √∫nico do item
    "Descri√ß√£o",  # Descri√ß√£o do item
    "Un.",  # Unidade de medida
    "Unit√°rio",  # Pre√ßo unit√°rio
    "Coment√°rio",  # Coment√°rios adicionais
    "Quantidade",  # Quantidade do item
    "Total",  # Valor total do item
]
ALTERNATIVE_COLUMNS = ["ID", "Un.", "Unit√°rio", "Quantidade"]  # Colunas m√≠nimas alternativas
COL_FILTRO = "Filtro"  # Nome da coluna usada para filtragem

# Metadados padr√£o
DEFAULT_METADATA_KEYS = {
    "codigo_upe": "upe",  # C√≥digo UPE
    "numero_agencia": "ag√™ncia|agencia",  # N√∫mero da ag√™ncia
    "nome_agencia": "nome da ag√™ncia|nome da agencia",  # Nome da ag√™ncia
    "total": "total",  # Total geral
    "contrato": "contrato",  # N√∫mero do contrato
    "versao": "vers√£o|versao",  # Vers√£o do documento
    "tipo": "tipo",  # Tipo do or√ßamento
    "quantidade_sinergias": "quantidade sinergias",  # Quantidade de sinergias
    "dono": "dono",  # Dono do or√ßamento
}

@dataclass
class FileInput:
    """
    Representa um arquivo de entrada com caminho e nome da aba opcional.

    Attributes:
        file_path (str): Caminho do arquivo.
        sheet_name (Optional[str]): Nome da aba a ser lida (padr√£o: "LPU").
    """
    file_path: str  # Caminho completo do arquivo
    sheet_name: Optional[str] = "LPU"  # Nome da aba a ser lida, padr√£o "LPU"

# Fun√ß√µes auxiliares

def normalize_values(values: list) -> list:
    """
    Normaliza uma lista de valores, removendo espa√ßos, convertendo para letras min√∫sculas
    e substituindo valores NaN ou vazios por strings vazias.

    Args:
        values (list): Lista de valores a serem normalizados.

    Returns:
        list: Lista de valores normalizados.
    """
    return [
        "" if pd.isna(val) or (isinstance(val, float) and math.isnan(val)) else str(val).strip().lower()
        for val in values  # Remove espa√ßos, converte para min√∫sculas e trata NaN
    ]

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Realiza o pr√©-processamento inicial dos dados, incluindo a remo√ß√£o de linhas totalmente em branco.

    Args:
        df (pd.DataFrame): DataFrame bruto lido da planilha.

    Returns:
        pd.DataFrame: DataFrame pr√©-processado.
    """
    return df.dropna(how="all").reset_index(drop=True)  # Remove linhas vazias e reseta o √≠ndice

def locate_table(
    df: pd.DataFrame,
    expected_columns: list = EXPECTED_COLUMNS,
    alternative_columns: list = ALTERNATIVE_COLUMNS,
) -> Tuple[Optional[int], Optional[int], Optional[list]]:
    """
    Detecta a posi√ß√£o (linha, coluna) onde o cabe√ßalho da tabela come√ßa.

    Args:
        df (pd.DataFrame): DataFrame contendo os dados da planilha.
        expected_columns (list): Lista de colunas esperadas no cabe√ßalho da tabela.
        alternative_columns (list): Lista alternativa m√≠nima de colunas aceitas.

    Returns:
        tuple: Uma tupla (linha, coluna, colunas_encontradas) indicando a posi√ß√£o do cabe√ßalho e as colunas encontradas,
               ou (None, None, None) se n√£o encontrado.
    """
    normalized_expected = [col.lower() for col in expected_columns]  # Normaliza colunas esperadas
    normalized_alternative = [col.lower() for col in alternative_columns]  # Normaliza colunas alternativas
    num_cols = len(expected_columns)  # N√∫mero de colunas esperadas

    for row in range(df.shape[0]):  # Itera sobre as linhas do DataFrame
        for col in range(df.shape[1] - num_cols + 1):  # Itera sobre as colunas poss√≠veis
            values = df.iloc[row, col : col + num_cols].tolist()  # Extrai valores da linha e colunas
            normalized = normalize_values(values)  # Normaliza os valores extra√≠dos

            if normalized == normalized_expected:  # Verifica se os valores correspondem √†s colunas esperadas
                return row, col, expected_columns
            if all(col in normalized for col in normalized_alternative):  # Verifica colunas alternativas
                return row, col, alternative_columns

    return None, None, None  # Retorna None se n√£o encontrar o cabe√ßalho

def find_metadata_value(
    row: pd.Series,
    col_idx: int,
    metadata_key: str,
    metadata: Dict[str, Any],
    df: pd.DataFrame,
    row_idx: int,
) -> None:
    """
    Busca e atribui um valor de metadado ao dicion√°rio, se ainda n√£o atribu√≠do.

    Args:
        row (pd.Series): Linha do DataFrame.
        col_idx (int): √çndice da coluna atual.
        metadata_key (str): Chave do metadado a ser buscado.
        metadata (dict): Dicion√°rio de metadados.
        df (pd.DataFrame): DataFrame completo para buscar o valor na linha seguinte.
        row_idx (int): √çndice da linha atual no DataFrame.
    """
    if metadata[metadata_key] is None:  # Verifica se o metadado j√° foi atribu√≠do
        if row_idx + 1 < len(df):  # Verifica se a pr√≥xima linha existe
            metadata[metadata_key] = df.iloc[row_idx + 1, col_idx]  # Atribui o valor da pr√≥xima linha
        else:
            metadata[metadata_key] = None  # Define como None se n√£o houver pr√≥xima linha

def extract_metadata(
    df: pd.DataFrame, metadata_keys: dict = DEFAULT_METADATA_KEYS
) -> Dict[str, Optional[Any]]:
    """
    Extrai metadados da tabela de or√ßamento de forma gen√©rica e din√¢mica.

    Args:
        df (pd.DataFrame): DataFrame contendo os dados da planilha.
        metadata_keys (dict): Dicion√°rio com as chaves de metadados e padr√µes de busca.

    Returns:
        dict: Dicion√°rio contendo os metadados extra√≠dos.
    """
    metadata = {key: None for key in metadata_keys}  # Inicializa o dicion√°rio de metadados

    for row_idx, row in df.iterrows():  # Itera sobre as linhas do DataFrame
        for col_idx, cell in enumerate(row):  # Itera sobre as c√©lulas da linha
            if pd.isna(cell):  # Ignora c√©lulas vazias
                continue

            cell_str = str(cell).strip().lower()  # Normaliza o valor da c√©lula

            for key, pattern in metadata_keys.items():  # Verifica padr√µes de metadados
                if metadata[key] is None and any(p in cell_str for p in pattern.split("|")):
                    find_metadata_value(row, col_idx, key, metadata, df, row_idx)  # Busca o valor do metadado

    return metadata  # Retorna o dicion√°rio de metadados

def extract_table(
    df: pd.DataFrame,
    header_row: int,
    first_col: int,
    columns_found: list,
    col_filter: str = COL_FILTRO,
) -> pd.DataFrame:
    """
    A partir da posi√ß√£o do cabe√ßalho, extrai a tabela at√© as linhas vazias.

    Args:
        df (pd.DataFrame): DataFrame contendo os dados da planilha.
        header_row (int): Linha onde o cabe√ßalho da tabela come√ßa.
        first_col (int): Coluna onde o cabe√ßalho da tabela come√ßa.
        columns_found (list): Lista de colunas encontradas no cabe√ßalho.
        col_filter (str): Nome da coluna usada para filtrar linhas vazias.

    Returns:
        pd.DataFrame: DataFrame contendo apenas a tabela extra√≠da e processada.
    """
    num_cols = len(columns_found)  # N√∫mero de colunas encontradas
    data = df.iloc[header_row + 1 :, first_col : first_col + num_cols].copy()  # Extrai os dados abaixo do cabe√ßalho
    data.columns = columns_found  # Define os nomes das colunas
    return post_process_table(data, col_filter=col_filter)  # Aplica p√≥s-processamento

def post_process_table(data: pd.DataFrame, col_filter: str = COL_FILTRO) -> pd.DataFrame:
    """
    Aplica filtros e p√≥s-processamentos em um DataFrame extra√≠do.

    Args:
        data (pd.DataFrame): DataFrame contendo os dados extra√≠dos da tabela.
        col_filter (str): Nome da coluna usada para filtrar linhas vazias.

    Returns:
        pd.DataFrame: DataFrame p√≥s-processado com filtros aplicados.
    """
    data = data.dropna(how="all")  # Remove linhas completamente vazias
    if col_filter in data.columns:  # Verifica se a coluna de filtro existe
        data = data[data[col_filter].str.lower() == "sim"]  # Filtra linhas onde o valor √© "sim"
    return data.reset_index(drop=True)  # Reseta o √≠ndice do DataFrame

def read_budget_table(
    file_path: str, sheet_name: str = DEFAULT_SHEET_NAME
) -> Tuple[pd.DataFrame, Dict[str, Optional[Any]]]:
    """
    L√™ a planilha (aba LPU) e retorna apenas a tabela de or√ßamento.

    Args:
        file_path (str): Caminho do arquivo da planilha.
        sheet_name (str): Nome da aba a ser lida.

    Returns:
        tuple: DataFrame contendo a tabela extra√≠da e dicion√°rio com os metadados.
    """
    raw_df = read_data(file_path, sheet_name=sheet_name, header=None)  # L√™ a planilha sem cabe√ßalho
    raw_df = preprocess_data(raw_df)  # Pr√©-processa os dados
    row, col, columns_found = locate_table(raw_df)  # Localiza o cabe√ßalho da tabela
    if row is None:
        raise ValueError("Cabe√ßalho da tabela n√£o encontrado na planilha.")
    metadata = extract_metadata(raw_df)  # Extrai os metadados
    table = extract_table(raw_df, row, col, columns_found)  # Extrai a tabela
    return table, metadata  # Retorna a tabela e os metadados

def orchestrate_budget_reader(*files: List[FileInput]) -> pd.DataFrame:
    """
    Orquestra a execu√ß√£o do budget_reader.

    Args:
        *files (List[FileInput]): Lista de inst√¢ncias FileInput contendo o caminho do arquivo e, opcionalmente, o nome da aba.

    Returns:
        pd.DataFrame: DataFrame concatenado de todas as tabelas processadas.
    """
    all_tables = []  # Lista para armazenar todas as tabelas processadas

    for file_input in files:  # Itera sobre os arquivos de entrada
        logger.info(f"Iniciando processamento do arquivo: {file_input.file_path}, aba: {file_input.sheet_name}")
        try:
            table, metadata = read_budget_table(file_input.file_path, sheet_name=file_input.sheet_name)  # L√™ a tabela
            table["source_file"] = Path(file_input.file_path).name  # Adiciona o nome do arquivo como coluna
            table["sheet_name"] = file_input.sheet_name  # Adiciona o nome da aba como coluna
            all_tables.append(table)  # Adiciona a tabela √† lista
            logger.success(f"Tabela extra√≠da com sucesso do arquivo: {file_input.file_path}, aba: {file_input.sheet_name}")
        except Exception as e:
            logger.error(f"Erro ao processar o arquivo {file_input.file_path}, aba {file_input.sheet_name}: {e}")

    if all_tables:  # Verifica se h√° tabelas processadas
        final_df = pd.concat(all_tables, ignore_index=True)  # Concatena todas as tabelas
        logger.success("Todas as tabelas foram concatenadas com sucesso.")
        logger.info(final_df)  # Loga o DataFrame final
        return final_df

    logger.warning("Nenhuma tabela foi processada com sucesso.")
    return pd.DataFrame()  # Retorna um DataFrame vazio se nenhuma tabela foi processada
